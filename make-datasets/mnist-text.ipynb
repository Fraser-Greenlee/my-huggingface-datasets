{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./x/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./x/', train=False, transform=transforms.ToTensor(), download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in train_dataset:\n",
    "    array = row[0][0].numpy()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def show_image(array):\n",
    "    pixels = (array * 255).astype(np.uint8)\n",
    "    image = Image.fromarray(pixels, 'L')\n",
    "    image.putdata(pixels)\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(img, factor: int):\n",
    "    \"\"\"\n",
    "        Perform max pooling with a (factor x factor) kernel\n",
    "    \"\"\"\n",
    "    ds_img = np.full((img.shape[0] // factor, img.shape[1] // factor), -float('inf'), dtype=img.dtype)\n",
    "    np.maximum.at(ds_img, (np.arange(img.shape[0])[:, None] // factor, np.arange(img.shape[1]) // factor), img)\n",
    "    return ds_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\n",
    "    max_pool(array, factor=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 down ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
      "01 down ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
      "02 down ! ! ! ! ! ! % % C L a ^ ! !\n",
      "03 down ! ! ! - ` ` ` ` ` Y ` Q ! !\n",
      "04 down ! ! ! % ` ` ` R ^ ! ! ! ! !\n",
      "05 down ! ! ! ! $ G ` ! ! ! ! ! ! !\n",
      "06 down ! ! ! ! ! # ` Y < ! ! ! ! !\n",
      "07 down ! ! ! ! ! ! 5 ` ` F ! ! ! !\n",
      "08 down ! ! ! ! ! ! ! % ` ` 1 ! ! !\n",
      "09 down ! ! ! ! ! ! F ` ` ` ! ! ! !\n",
      "10 down ! ! ! ! 1 ` ` ` ` 4 ! ! ! !\n",
      "11 down ! ! L ` ` ` ` 5 ! ! ! ! ! !\n",
      "12 down ! ! ` ` V B ! ! ! ! ! ! ! !\n",
      "13 down ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
      "13 up ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
      "12 up ! ! ` ` V B ! ! ! ! ! ! ! !\n",
      "11 up ! ! L ` ` ` ` 5 ! ! ! ! ! !\n",
      "10 up ! ! ! ! 1 ` ` ` ` 4 ! ! ! !\n",
      "09 up ! ! ! ! ! ! F ` ` ` ! ! ! !\n",
      "08 up ! ! ! ! ! ! ! % ` ` 1 ! ! !\n",
      "07 up ! ! ! ! ! ! 5 ` ` F ! ! ! !\n",
      "06 up ! ! ! ! ! # ` Y < ! ! ! ! !\n",
      "05 up ! ! ! ! $ G ` ! ! ! ! ! ! !\n",
      "04 up ! ! ! % ` ` ` R ^ ! ! ! ! !\n",
      "03 up ! ! ! - ` ` ` ` ` Y ` Q ! !\n",
      "02 up ! ! ! ! ! ! % % C L a ^ ! !\n",
      "01 up ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
      "00 up ! ! ! ! ! ! ! ! ! ! ! ! ! !\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "pixels = max_pool(array, factor=2)\n",
    "\n",
    "\n",
    "width = pixels.shape[0]\n",
    "height = pixels.shape[1]\n",
    "\n",
    "lines = []\n",
    "\n",
    "for y in range(height):\n",
    "    split = ['%02d down' % y]\n",
    "\n",
    "    for x in range(width):\n",
    "        brightness = pixels[y, x]\n",
    "\n",
    "        s = '~'\n",
    "        \n",
    "        mBrightness = math.floor(brightness * 64)\n",
    "        s = chr(mBrightness + 33)\n",
    "\n",
    "        split.append(s)\n",
    "\n",
    "    lines.append(' '.join(split))\n",
    "\n",
    "print('\\n'.join(lines))\n",
    "\n",
    "reversed = []\n",
    "for line in lines:\n",
    "    reversed.insert(0, (line.replace(' down ', ' up ', 1)))\n",
    "print('\\n'.join(reversed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''00 down ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
    "01 down ! ! ! ! ! ! ! ! ! ! ! ! ! !\n",
    "02 down ! ! ! ! ! ! % % C L a ^ ! !\n",
    "03 down ! ! ! - ` ` ` ` ` Y ` Q ! !\n",
    "04 down ! ! ! % ` ` ` R ^ ! ! ! ! !\n",
    "05 down ! ! ! ! $ G ` ! ! ! ! ! ! !\n",
    "06 down ! ! ! ! ! # ` Y < ! ! ! ! !\n",
    "07 down ! ! ! ! ! ! 5 ` ` F ! ! ! !\n",
    "08 down ! ! ! ! ! ! ! % ` ` 1 ! ! !\n",
    "09 down ! ! ! ! ! ! F ` ` ` ! ! ! !\n",
    "10 down ! ! ! ! 1 ` ` ` ` 4 ! ! ! !\n",
    "11 down ! ! L ` ` ` ` 5 ! ! ! ! ! !\n",
    "12 down ! ! ` ` V B ! ! ! ! ! ! ! !\n",
    "13 down ! ! ! ! ! ! ! ! ! ! ! ! ! !'''\n",
    "\n",
    "lines = text.split('\\n')\n",
    "pixels = np.zeros((len(lines), len(lines[0].split(' ')) - 2))\n",
    "\n",
    "for y, line in enumerate(lines):\n",
    "    tokens = line.split(' ')\n",
    "    assert(tokens[1] == 'down')\n",
    "    \n",
    "    pixel_tokens = tokens[2:]\n",
    "    for x, token in enumerate(pixel_tokens):\n",
    "        pixels[y, x] = ord(token) - 33\n",
    "\n",
    "show_image(\n",
    "    pixels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make JSON dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_text(pixels: np.array):\n",
    "    '''\n",
    "        Takes a 2D array of pixel brightness, converts to text using 64 tokens to represent all brightness values.\n",
    "    '''\n",
    "    pixels = max_pool(pixels, factor=2)\n",
    "    \n",
    "    width = pixels.shape[0]\n",
    "    height = pixels.shape[1]\n",
    "\n",
    "    lines = []\n",
    "\n",
    "    for y in range(height):\n",
    "        split = ['%02d down' % y]\n",
    "\n",
    "        for x in range(width):\n",
    "            brightness = pixels[y, x]\n",
    "\n",
    "            s = '~'\n",
    "\n",
    "            mBrightness = math.floor(brightness * 64)\n",
    "            s = chr(mBrightness + 33)\n",
    "\n",
    "            split.append(s)\n",
    "\n",
    "        lines.append(' '.join(split))\n",
    "\n",
    "    reversed_lines = []\n",
    "    for line in lines:\n",
    "        reversed_lines.insert(0, (line.replace(' down ', ' up ', 1)))\n",
    "\n",
    "    return ['\\n'.join(lines), '\\n'.join(reversed_lines)]\n",
    "\n",
    "def text_to_array(text: str):\n",
    "    lines = text.split('\\n')\n",
    "    pixels = np.zeros((len(lines), len(lines[0].split(' ')) - 2))\n",
    "\n",
    "    for y, line in enumerate(lines):\n",
    "        tokens = line.split(' ')\n",
    "        assert(tokens[1] == 'down')\n",
    "        pixel_tokens = tokens[2:]\n",
    "        for x, token in enumerate(pixel_tokens):\n",
    "            pixels[y, x] = ord(token) - 33\n",
    "\n",
    "    return pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./x/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./x/', train=False, transform=transforms.ToTensor(), download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [01:17<00:00, 771.42it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "training_data = []\n",
    "\n",
    "for tensor, label in tqdm(train_dataset):\n",
    "    array = tensor.numpy()[0]\n",
    "    up, down = array_to_text(array)\n",
    "    training_data += [{'text': up, 'label': label}, {'text': down, 'label': label}]\n",
    "\n",
    "with open('mnsit-text-train.json', 'w') as f:\n",
    "    for line in training_data:\n",
    "        f.write(json.dumps(line) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 976.85it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "\n",
    "for tensor, label in tqdm(test_dataset):\n",
    "    array = tensor.numpy()[0]\n",
    "    up, down = array_to_text(array)\n",
    "    test_data += [{'text': up, 'label': label}, {'text': down, 'label': label}]\n",
    "\n",
    "with open('mnsit-text-test.json', 'w') as f:\n",
    "    for line in test_data:\n",
    "        f.write(json.dumps(line) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:26<00:00, 2251.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "training_data = []\n",
    "\n",
    "for tensor, label in tqdm(train_dataset):\n",
    "    array = max_pool(tensor.numpy()[0], factor=2)\n",
    "    up, down = array_to_text(array)\n",
    "    training_data += [{'text': up, 'label': label}, {'text': down, 'label': label}]\n",
    "\n",
    "with open('mnsit-text-small-train.json', 'w') as f:\n",
    "    for line in training_data:\n",
    "        f.write(json.dumps(line) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:04<00:00, 2230.55it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "\n",
    "for tensor, label in tqdm(test_dataset):\n",
    "    array = max_pool(tensor.numpy()[0], factor=2)\n",
    "    up, down = array_to_text(array)\n",
    "    test_data += [{'text': up, 'label': label}, {'text': down, 'label': label}]\n",
    "\n",
    "with open('mnsit-text-small-test.json', 'w') as f:\n",
    "    for line in test_data:\n",
    "        f.write(json.dumps(line) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
